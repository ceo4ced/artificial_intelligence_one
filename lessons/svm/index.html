<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Support Vector Machines - Interactive Lesson</title>
<style>
* { margin: 0; padding: 0; box-sizing: border-box; }
body { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Arial, sans-serif; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); min-height: 100vh; padding: 0; }
.nav-header { background: #2d3748; padding: 15px 30px; box-shadow: 0 2px 10px rgba(0,0,0,0.3); display: flex; justify-content: space-between; align-items: center; }
.nav-header a { color: #90cdf4; text-decoration: none; font-weight: 600; font-size: 1.1em; }
.nav-title { color: #fff; font-size: 1.2em; font-weight: 700; }
.container { max-width: 1400px; margin: 20px auto; background: #fff; border-radius: 15px; padding: 30px; box-shadow: 0 20px 60px rgba(0,0,0,0.3); }
h1 { text-align: center; color: #2d3748; font-size: 2.5em; margin-bottom: 20px; }
.intro { background: #e3f2fd; padding: 20px; border-radius: 10px; margin-bottom: 30px; line-height: 1.6; }
.intro h2 { color: #1976d2; margin-bottom: 10px; }
.content-section { margin: 30px 0; }
.content-section h2 { color: #2d3748; margin-bottom: 15px; font-size: 1.8em; }
.content-section h3 { color: #667eea; margin: 20px 0 10px 0; font-size: 1.4em; }
.content-section p { line-height: 1.8; color: #4a5568; margin-bottom: 15px; }
.canvas-container { text-align: center; margin: 30px 0; }
canvas { border: 2px solid #ddd; border-radius: 8px; background: #fafafa; max-width: 100%; }
.demo-button { background: #667eea; color: #fff; padding: 12px 24px; border: none; border-radius: 8px; font-weight: 600; cursor: pointer; margin: 10px 5px; transition: all 0.3s; }
.demo-button:hover { background: #5568d3; transform: scale(1.05); }
.concept-grid { display: grid; grid-template-columns: repeat(auto-fit, minmax(300px, 1fr)); gap: 20px; margin: 20px 0; }
.concept-card { background: #f8f9fa; padding: 25px; border-radius: 10px; border-left: 4px solid #667eea; }
.concept-card h4 { color: #667eea; margin-bottom: 12px; font-size: 1.3em; }
.concept-card p { color: #4a5568; line-height: 1.7; }
.example-box { background: #fff9c4; padding: 20px; border-radius: 8px; margin: 20px 0; border-left: 4px solid #fbc02d; }
.example-box h4 { color: #f57c00; margin-bottom: 10px; }
.key-concepts { background: #e8f5e9; padding: 20px; border-radius: 8px; margin: 20px 0; }
.key-concepts h3 { color: #2e7d32; margin-bottom: 15px; }
.key-concepts ul { margin-left: 20px; line-height: 1.8; }
.interactive-demo { background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: #fff; padding: 25px; border-radius: 10px; margin: 30px 0; text-align: center; }
.demo-controls { margin: 20px 0; }
.kernel-selector { display: flex; justify-content: center; gap: 10px; margin: 20px 0; }
.kernel-btn { background: #fff; color: #667eea; padding: 10px 20px; border: 2px solid #667eea; border-radius: 8px; cursor: pointer; font-weight: 600; transition: all 0.3s; }
.kernel-btn.active { background: #667eea; color: #fff; }
.formula-box { background: #2d3748; color: #fff; padding: 20px; border-radius: 8px; margin: 20px 0; font-family: 'Courier New', monospace; overflow-x: auto; }
</style>
</head>
<body>
<nav class="nav-header">
    <div class="nav-title">‚ö° Support Vector Machines</div>
    <a href="../../index.html">‚Üê Back to Home</a>
</nav>
<div class="container">
    <h1>‚ö° Support Vector Machines (SVM)</h1>

    <div class="intro">
        <h2>What are Support Vector Machines?</h2>
        <p>
            Support Vector Machines (SVM) are powerful machine learning algorithms used for classification
            and regression. They work by finding the optimal boundary (hyperplane) that best separates
            different classes of data with maximum margin.
        </p>
        <p>
            Think of SVM as drawing the best possible line (or curve) between two groups of points,
            ensuring that the line is as far as possible from the nearest points on both sides.
            This makes SVMs very effective at creating robust decision boundaries.
        </p>
    </div>

    <div class="content-section">
        <h2>Core Concepts</h2>

        <div class="concept-grid">
            <div class="concept-card">
                <h4>üìè Hyperplane</h4>
                <p>
                    The decision boundary that separates different classes. In 2D, it's a line.
                    In 3D, it's a plane. In higher dimensions, it's called a hyperplane.
                </p>
            </div>

            <div class="concept-card">
                <h4>üéØ Support Vectors</h4>
                <p>
                    The data points closest to the hyperplane. These are the critical points that
                    define the position and orientation of the hyperplane. Only these points matter
                    for finding the optimal boundary!
                </p>
            </div>

            <div class="concept-card">
                <h4>üìê Margin</h4>
                <p>
                    The distance between the hyperplane and the nearest support vectors. SVM tries
                    to maximize this margin, creating a "safety buffer" that makes the classifier
                    more robust to new data.
                </p>
            </div>

            <div class="concept-card">
                <h4>üé≠ Kernel Trick</h4>
                <p>
                    A technique to handle non-linearly separable data. The kernel transforms data
                    into a higher dimension where a linear separation becomes possible, without
                    actually computing the transformation explicitly.
                </p>
            </div>
        </div>
    </div>

    <div class="canvas-container">
        <h2 style="margin-bottom: 20px;">Interactive Visualization: SVM in Action</h2>
        <canvas id="svmCanvas" width="800" height="500"></canvas>

        <div class="kernel-selector">
            <button class="kernel-btn active" onclick="changeKernel('linear')">Linear Kernel</button>
            <button class="kernel-btn" onclick="changeKernel('rbf')">RBF Kernel</button>
            <button class="kernel-btn" onclick="changeKernel('polynomial')">Polynomial Kernel</button>
        </div>

        <div class="demo-controls">
            <button class="demo-button" onclick="generateLinearData()">Linear Data</button>
            <button class="demo-button" onclick="generateNonLinearData()">Non-Linear Data</button>
            <button class="demo-button" onclick="generateCircularData()">Circular Data</button>
            <button class="demo-button" onclick="showSolution()">Show SVM Solution</button>
        </div>

        <div id="explanation" style="margin-top: 20px; padding: 20px; background: #f8f9fa; border-radius: 8px; text-align: left;">
            <strong>Current Setup:</strong> Linear kernel with linearly separable data.
            Click "Show SVM Solution" to see the optimal hyperplane and margin.
        </div>
    </div>

    <div class="content-section">
        <h2>How SVM Works: Step by Step</h2>

        <div class="example-box">
            <h4>Step 1: Plot the Data</h4>
            <p>
                Start with labeled training data. Each point belongs to one of two classes (e.g., red or blue).
            </p>
        </div>

        <div class="example-box">
            <h4>Step 2: Find Candidate Hyperplanes</h4>
            <p>
                There are many possible lines that could separate the classes. SVM needs to find the best one.
            </p>
        </div>

        <div class="example-box">
            <h4>Step 3: Maximize the Margin</h4>
            <p>
                SVM chooses the hyperplane that has the maximum distance to the nearest points of both classes.
                This creates the widest "street" between the classes.
            </p>
        </div>

        <div class="example-box">
            <h4>Step 4: Identify Support Vectors</h4>
            <p>
                The points that lie on the margin boundaries are the support vectors. These are the only
                points that matter - you could remove all other points and still get the same hyperplane!
            </p>
        </div>

        <div class="example-box">
            <h4>Step 5: Apply Kernel (if needed)</h4>
            <p>
                If the data isn't linearly separable, apply a kernel function to transform it into a higher
                dimension where linear separation is possible.
            </p>
        </div>
    </div>

    <div class="content-section">
        <h2>Types of Kernels</h2>

        <div class="concept-card" style="margin: 20px 0;">
            <h4>Linear Kernel</h4>
            <p>
                <strong>Formula:</strong> K(x, y) = x ¬∑ y<br><br>
                Best for linearly separable data. Fast and simple. Use when your data can be separated by
                a straight line (or hyperplane in higher dimensions).
            </p>
        </div>

        <div class="concept-card" style="margin: 20px 0;">
            <h4>Polynomial Kernel</h4>
            <p>
                <strong>Formula:</strong> K(x, y) = (x ¬∑ y + c)^d<br><br>
                Handles curved decision boundaries. The degree (d) controls the flexibility. Good for
                data with polynomial relationships.
            </p>
        </div>

        <div class="concept-card" style="margin: 20px 0;">
            <h4>RBF (Radial Basis Function) Kernel</h4>
            <p>
                <strong>Formula:</strong> K(x, y) = exp(-Œ≥||x - y||¬≤)<br><br>
                Most popular kernel for non-linear data. Can handle complex, circular, or irregular
                decision boundaries. Very flexible and powerful.
            </p>
        </div>
    </div>

    <div class="content-section">
        <h2>Mathematical Foundation</h2>

        <div class="formula-box">
<pre>
SVM Optimization Problem:
Maximize: margin = 2 / ||w||
Subject to: y_i(w¬∑x_i + b) ‚â• 1 for all training points

Where:
- w = weight vector (defines hyperplane orientation)
- b = bias (defines hyperplane position)
- y_i = class label (-1 or +1)
- x_i = feature vector of data point i

The hyperplane equation: w¬∑x + b = 0

Decision function: sign(w¬∑x + b)
- If w¬∑x + b > 0 ‚Üí Class +1
- If w¬∑x + b < 0 ‚Üí Class -1
</pre>
        </div>
    </div>

    <div class="content-section">
        <h2>Real-World Applications</h2>

        <div class="concept-grid">
            <div class="example-box" style="background: #e8f5e9; border-left-color: #4CAF50;">
                <h4 style="color: #2e7d32;">üè• Medical Diagnosis</h4>
                <p style="color: #1b5e20;">
                    Classifying medical images (cancer vs. non-cancer), predicting disease risk based
                    on patient features, and identifying protein structures.
                </p>
            </div>

            <div class="example-box" style="background: #e8f5e9; border-left-color: #4CAF50;">
                <h4 style="color: #2e7d32;">‚úâÔ∏è Spam Detection</h4>
                <p style="color: #1b5e20;">
                    Email filtering systems use SVMs to classify messages as spam or legitimate based
                    on features like keywords, sender information, and patterns.
                </p>
            </div>

            <div class="example-box" style="background: #e8f5e9; border-left-color: #4CAF50;">
                <h4 style="color: #2e7d32;">üë§ Face Recognition</h4>
                <p style="color: #1b5e20;">
                    Identifying individuals from facial features. SVMs can handle high-dimensional
                    feature spaces effectively, making them ideal for face recognition.
                </p>
            </div>

            <div class="example-box" style="background: #e8f5e9; border-left-color: #4CAF50;">
                <h4 style="color: #2e7d32;">üìù Text Classification</h4>
                <p style="color: #1b5e20;">
                    Categorizing documents, sentiment analysis, topic detection, and language
                    identification based on text features.
                </p>
            </div>

            <div class="example-box" style="background: #e8f5e9; border-left-color: #4CAF50;">
                <h4 style="color: #2e7d32;">üñºÔ∏è Image Classification</h4>
                <p style="color: #1b5e20;">
                    Object detection, scene recognition, and image segmentation using pixel features
                    and pattern recognition.
                </p>
            </div>

            <div class="example-box" style="background: #e8f5e9; border-left-color: #4CAF50;">
                <h4 style="color: #2e7d32;">üí∞ Financial Forecasting</h4>
                <p style="color: #1b5e20;">
                    Stock market prediction, credit scoring, fraud detection, and risk assessment
                    based on financial indicators.
                </p>
            </div>
        </div>
    </div>

    <div class="content-section">
        <h2>Advantages and Disadvantages</h2>

        <div class="concept-grid">
            <div class="concept-card" style="border-left-color: #4CAF50;">
                <h4 style="color: #4CAF50;">‚úÖ Advantages</h4>
                <ul style="margin-left: 20px; line-height: 1.8;">
                    <li>Effective in high-dimensional spaces</li>
                    <li>Memory efficient (only uses support vectors)</li>
                    <li>Versatile (different kernels for different data)</li>
                    <li>Works well with clear margin of separation</li>
                    <li>Resistant to overfitting (maximizing margin)</li>
                </ul>
            </div>

            <div class="concept-card" style="border-left-color: #f44336;">
                <h4 style="color: #f44336;">‚ö†Ô∏è Disadvantages</h4>
                <ul style="margin-left: 20px; line-height: 1.8;">
                    <li>Slow on large datasets (training time)</li>
                    <li>Requires careful kernel selection</li>
                    <li>Sensitive to feature scaling</li>
                    <li>No probability estimates (just classifications)</li>
                    <li>Difficult to interpret (especially with kernels)</li>
                </ul>
            </div>
        </div>
    </div>

    <div class="interactive-demo">
        <h2 style="margin-bottom: 15px;">üéÆ Ready to Practice?</h2>
        <p style="margin-bottom: 20px;">Try the Margin Maximizer game to find optimal decision boundaries!</p>
        <a href="../../games/svm/index.html" style="text-decoration: none;">
            <button class="demo-button" style="background: #fff; color: #667eea; font-size: 1.1em;">
                Play Margin Maximizer Game ‚Üí
            </button>
        </a>
    </div>

    <div class="key-concepts">
        <h3>Key Takeaways</h3>
        <ul>
            <li>SVMs find the optimal hyperplane that maximizes the margin between classes</li>
            <li>Support vectors are the critical data points that define the decision boundary</li>
            <li>The kernel trick allows SVMs to handle non-linear decision boundaries</li>
            <li>Different kernels (linear, polynomial, RBF) suit different types of data</li>
            <li>SVMs are effective for high-dimensional data and resist overfitting</li>
            <li>Real-world applications include medical diagnosis, spam detection, and image recognition</li>
        </ul>
    </div>
</div>

<script>
const canvas = document.getElementById('svmCanvas');
const ctx = canvas.getContext('2d');

let currentKernel = 'linear';
let dataPoints = [];
let showingSolution = false;

class DataPoint {
    constructor(x, y, label) {
        this.x = x;
        this.y = y;
        this.label = label; // -1 or 1
    }
}

function generateLinearData() {
    dataPoints = [];
    showingSolution = false;

    // Class 1 (blue, label = 1)
    for (let i = 0; i < 25; i++) {
        const x = 150 + Math.random() * 200;
        const y = 100 + Math.random() * 150 + (x - 150) * 0.3;
        dataPoints.push(new DataPoint(x, y, 1));
    }

    // Class 2 (red, label = -1)
    for (let i = 0; i < 25; i++) {
        const x = 450 + Math.random() * 200;
        const y = 250 + Math.random() * 150 + (x - 450) * 0.3;
        dataPoints.push(new DataPoint(x, y, -1));
    }

    drawCanvas();
    updateExplanation('Linear kernel with linearly separable data. Perfect for a straight-line decision boundary.');
}

function generateNonLinearData() {
    dataPoints = [];
    showingSolution = false;

    // Class 1 (blue) - curved pattern
    for (let i = 0; i < 30; i++) {
        const x = 200 + Math.random() * 400;
        const y = 150 + Math.sin(x / 100) * 80 + Math.random() * 50;
        dataPoints.push(new DataPoint(x, y, 1));
    }

    // Class 2 (red) - opposite curved pattern
    for (let i = 0; i < 30; i++) {
        const x = 200 + Math.random() * 400;
        const y = 350 + Math.sin(x / 100) * 80 + Math.random() * 50;
        dataPoints.push(new DataPoint(x, y, -1));
    }

    drawCanvas();
    updateExplanation('Non-linear data requiring polynomial or RBF kernel. A straight line cannot separate these classes.');
}

function generateCircularData() {
    dataPoints = [];
    showingSolution = false;

    const centerX = 400;
    const centerY = 250;

    // Class 1 (blue) - inner circle
    for (let i = 0; i < 30; i++) {
        const angle = Math.random() * Math.PI * 2;
        const radius = 50 + Math.random() * 40;
        const x = centerX + Math.cos(angle) * radius;
        const y = centerY + Math.sin(angle) * radius;
        dataPoints.push(new DataPoint(x, y, 1));
    }

    // Class 2 (red) - outer ring
    for (let i = 0; i < 40; i++) {
        const angle = Math.random() * Math.PI * 2;
        const radius = 120 + Math.random() * 60;
        const x = centerX + Math.cos(angle) * radius;
        const y = centerY + Math.sin(angle) * radius;
        dataPoints.push(new DataPoint(x, y, -1));
    }

    drawCanvas();
    updateExplanation('Circular data - ideal for RBF kernel. The classes form concentric patterns that linear boundaries cannot handle.');
}

function drawCanvas() {
    ctx.clearRect(0, 0, canvas.width, canvas.height);

    // Draw grid
    ctx.strokeStyle = '#e0e0e0';
    ctx.lineWidth = 1;
    for (let i = 0; i < canvas.width; i += 50) {
        ctx.beginPath();
        ctx.moveTo(i, 0);
        ctx.lineTo(i, canvas.height);
        ctx.stroke();
    }
    for (let i = 0; i < canvas.height; i += 50) {
        ctx.beginPath();
        ctx.moveTo(0, i);
        ctx.lineTo(canvas.width, i);
        ctx.stroke();
    }

    // Draw data points
    dataPoints.forEach(point => {
        ctx.fillStyle = point.label === 1 ? 'rgba(33, 150, 243, 0.8)' : 'rgba(244, 67, 54, 0.8)';
        ctx.beginPath();
        ctx.arc(point.x, point.y, 6, 0, Math.PI * 2);
        ctx.fill();

        if (showingSolution) {
            // Highlight support vectors with rings
            const isSupportVector = checkIfSupportVector(point);
            if (isSupportVector) {
                ctx.strokeStyle = point.label === 1 ? 'rgba(33, 150, 243, 1)' : 'rgba(244, 67, 54, 1)';
                ctx.lineWidth = 3;
                ctx.beginPath();
                ctx.arc(point.x, point.y, 10, 0, Math.PI * 2);
                ctx.stroke();
            }
        }
    });

    if (showingSolution) {
        drawSVMSolution();
    }
}

function checkIfSupportVector(point) {
    // Simplified: mark points near the decision boundary as support vectors
    if (dataPoints.length === 0) return false;

    // For demo purposes, just mark a few points near the middle
    if (currentKernel === 'linear') {
        return Math.abs(point.x - 400) < 100 && Math.abs(point.y - 250) < 80;
    }
    return false;
}

function drawSVMSolution() {
    ctx.lineWidth = 3;

    if (currentKernel === 'linear') {
        // Draw hyperplane
        ctx.strokeStyle = '#4CAF50';
        ctx.beginPath();
        ctx.moveTo(250, 100);
        ctx.lineTo(550, 400);
        ctx.stroke();

        // Draw margins
        ctx.strokeStyle = '#4CAF50';
        ctx.setLineDash([10, 5]);
        ctx.lineWidth = 2;

        ctx.beginPath();
        ctx.moveTo(200, 100);
        ctx.lineTo(500, 400);
        ctx.stroke();

        ctx.beginPath();
        ctx.moveTo(300, 100);
        ctx.lineTo(600, 400);
        ctx.stroke();

        ctx.setLineDash([]);

        // Label
        ctx.fillStyle = '#4CAF50';
        ctx.font = 'bold 14px Arial';
        ctx.fillText('Decision Boundary', 420, 200);
        ctx.fillText('Margin', 320, 150);

    } else if (currentKernel === 'rbf') {
        // Draw circular decision boundary for RBF
        ctx.strokeStyle = '#4CAF50';
        ctx.beginPath();
        ctx.arc(400, 250, 100, 0, Math.PI * 2);
        ctx.stroke();

        // Draw margin circles
        ctx.setLineDash([10, 5]);
        ctx.beginPath();
        ctx.arc(400, 250, 85, 0, Math.PI * 2);
        ctx.stroke();

        ctx.beginPath();
        ctx.arc(400, 250, 115, 0, Math.PI * 2);
        ctx.stroke();
        ctx.setLineDash([]);

    } else if (currentKernel === 'polynomial') {
        // Draw curved boundary
        ctx.strokeStyle = '#4CAF50';
        ctx.beginPath();
        ctx.moveTo(200, 150);
        for (let x = 200; x <= 600; x += 5) {
            const y = 250 + Math.sin((x - 200) / 100) * 80;
            ctx.lineTo(x, y);
        }
        ctx.stroke();
    }
}

function showSolution() {
    showingSolution = true;
    drawCanvas();
}

function changeKernel(kernel) {
    currentKernel = kernel;
    showingSolution = false;

    // Update button states
    document.querySelectorAll('.kernel-btn').forEach(btn => {
        btn.classList.remove('active');
    });
    event.target.classList.add('active');

    drawCanvas();

    const kernelInfo = {
        'linear': 'Linear kernel: Best for linearly separable data. Creates straight decision boundaries.',
        'rbf': 'RBF kernel: Handles circular and complex patterns. Most versatile for non-linear data.',
        'polynomial': 'Polynomial kernel: Creates curved boundaries. Good for polynomial relationships.'
    };

    updateExplanation(kernelInfo[kernel]);
}

function updateExplanation(text) {
    document.getElementById('explanation').innerHTML = '<strong>Current Setup:</strong> ' + text;
}

// Initialize with linear data
generateLinearData();
</script>
</body>
</html>
