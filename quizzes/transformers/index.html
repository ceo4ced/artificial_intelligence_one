<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Transformer Networks Quiz</title>
<style>
* { margin: 0; padding: 0; box-sizing: border-box; }
body { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Arial, sans-serif; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); min-height: 100vh; padding: 0; }
.nav-header { background: #2d3748; padding: 15px 30px; box-shadow: 0 2px 10px rgba(0,0,0,0.3); display: flex; justify-content: space-between; align-items: center; }
.nav-header a { color: #90cdf4; text-decoration: none; font-weight: 600; font-size: 1.1em; }
.nav-title { color: #fff; font-size: 1.2em; font-weight: 700; }
.container { max-width: 900px; margin: 20px auto; background: #fff; border-radius: 15px; padding: 40px; box-shadow: 0 20px 60px rgba(0,0,0,0.3); }
h1 { text-align: center; color: #2d3748; font-size: 2.5em; margin-bottom: 15px; }
.subtitle { text-align: center; color: #666; margin-bottom: 30px; font-size: 1.1em; }
.question-card { background: #f8f9fa; padding: 25px; border-radius: 10px; margin: 20px 0; border-left: 4px solid #667eea; }
.question-card.answered-correct { border-left-color: #4CAF50; background: #f1f8f4; }
.question-card.answered-wrong { border-left-color: #f44336; background: #ffebee; }
.question-number { color: #667eea; font-weight: 600; margin-bottom: 10px; }
.question-text { font-size: 1.2em; color: #2d3748; margin-bottom: 20px; line-height: 1.6; }
.options { display: flex; flex-direction: column; gap: 12px; }
.option { background: #fff; padding: 15px 20px; border-radius: 8px; border: 2px solid #e0e0e0; cursor: pointer; transition: all 0.3s; }
.option:hover { border-color: #667eea; transform: translateX(5px); }
.option.selected { border-color: #667eea; background: #e3f2fd; }
.option.correct { border-color: #4CAF50; background: #c8e6c9; }
.option.wrong { border-color: #f44336; background: #ffcdd2; }
.option.disabled { cursor: not-allowed; opacity: 0.7; }
.explanation { margin-top: 15px; padding: 15px; background: #fff9c4; border-radius: 6px; border-left: 3px solid #fbc02d; display: none; }
.explanation.show { display: block; }
.explanation strong { color: #f57c00; }
.progress-bar { background: #e0e0e0; height: 10px; border-radius: 5px; margin: 20px 0; overflow: hidden; }
.progress-fill { background: linear-gradient(90deg, #667eea, #764ba2); height: 100%; transition: width 0.3s; }
.quiz-actions { display: flex; gap: 15px; justify-content: center; margin: 30px 0; }
button { padding: 15px 30px; border: none; border-radius: 8px; cursor: pointer; font-weight: 600; font-size: 1.05em; transition: all 0.3s; }
.btn-primary { background: #4CAF50; color: #fff; }
.btn-primary:hover { background: #45a049; transform: scale(1.05); }
.btn-primary:disabled { background: #ccc; cursor: not-allowed; transform: none; }
.btn-secondary { background: #2196F3; color: #fff; }
.btn-secondary:hover { background: #1976d2; }
.results-card { background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: #fff; padding: 40px; border-radius: 15px; text-align: center; margin: 30px 0; }
.results-card h2 { font-size: 2.5em; margin-bottom: 20px; }
.score-display { font-size: 4em; font-weight: bold; margin: 20px 0; }
.results-grid { display: grid; grid-template-columns: repeat(auto-fit, minmax(150px, 1fr)); gap: 20px; margin: 30px 0; }
.result-stat { background: rgba(255,255,255,0.2); padding: 20px; border-radius: 10px; }
.result-stat-value { font-size: 2em; font-weight: bold; }
.result-stat-label { margin-top: 8px; opacity: 0.9; }
</style>
</head>
<body>
<nav class="nav-header">
    <div class="nav-title">Transformer Networks Quiz</div>
    <div>
        <a href="../../lessons/transformers/index.html" style="margin-right: 20px;">View Lesson</a>
        <a href="../index.html">Back to Quizzes</a>
    </div>
</nav>
<div class="container">
    <h1>Transformer Networks Quiz</h1>
    <p class="subtitle">Test your understanding of self-attention, multi-head attention, and transformer architectures</p>

    <div class="progress-bar">
        <div class="progress-fill" id="progressBar" style="width: 0%"></div>
    </div>

    <div id="quizContent"></div>

    <div class="quiz-actions" id="quizActions">
        <button class="btn-primary" id="submitBtn" onclick="submitQuiz()" disabled>Submit Quiz</button>
        <button class="btn-secondary" onclick="retakeQuiz()">Retake Quiz</button>
    </div>
</div>

<script>
const quizData = {
    id: 'transformers',
    questions: [
        {
            question: "What is the key innovation that transformers introduced?",
            options: [
                "Using more layers",
                "Self-attention mechanism that processes entire sequences in parallel",
                "Faster training only",
                "Smaller model size"
            ],
            correct: 1,
            explanation: "Transformers introduced the self-attention mechanism which allows the model to process all elements of a sequence simultaneously and learn relationships between all positions in parallel."
        },
        {
            question: "What is self-attention?",
            options: [
                "The network focusing on itself",
                "A mechanism that determines how much each part of the input should attend to other parts",
                "A meditation technique for AI",
                "Error checking in the network"
            ],
            correct: 1,
            explanation: "Self-attention computes relationships between all elements in a sequence, determining how much each element should 'attend to' or focus on every other element when building its representation."
        },
        {
            question: "What are the three components computed in self-attention?",
            options: [
                "Input, output, and hidden",
                "Query, Key, and Value vectors",
                "Encoder, decoder, and embedding",
                "Start, middle, and end"
            ],
            correct: 1,
            explanation: "Self-attention computes Query (what we're looking for), Key (what each position offers), and Value (the actual content) vectors for each element to determine attention weights and create representations."
        },
        {
            question: "What is multi-head attention?",
            options: [
                "Using multiple computers",
                "Running multiple attention mechanisms in parallel to capture different types of relationships",
                "Having many output layers",
                "Processing multiple languages"
            ],
            correct: 1,
            explanation: "Multi-head attention runs several attention mechanisms in parallel, each learning to focus on different aspects or relationships in the data, then combines their outputs for richer representations."
        },
        {
            question: "Why do transformers need positional encoding?",
            options: [
                "To save memory",
                "Because self-attention has no inherent notion of sequence order",
                "To make training faster",
                "To reduce model size"
            ],
            correct: 1,
            explanation: "Unlike RNNs that process sequences step-by-step, transformers process all positions simultaneously. Positional encoding adds information about each element's position so the model knows the sequence order."
        },
        {
            question: "What advantage do transformers have over RNNs?",
            options: [
                "They use less memory",
                "They can process sequences in parallel and capture long-range dependencies better",
                "They are simpler to understand",
                "They train on less data"
            ],
            correct: 1,
            explanation: "Transformers process all sequence elements in parallel (unlike RNNs' sequential processing), making them faster to train and better at capturing long-range dependencies without vanishing gradients."
        },
        {
            question: "What is the encoder in a transformer?",
            options: [
                "A compression tool",
                "The part that processes input and builds contextualized representations",
                "The final output layer",
                "A data storage component"
            ],
            correct: 1,
            explanation: "The encoder processes the input sequence through multiple layers of self-attention and feedforward networks, building rich, contextualized representations of each element."
        },
        {
            question: "What is the decoder in a transformer?",
            options: [
                "A decompression tool",
                "The part that generates output sequences using encoder representations and self-attention",
                "The input layer",
                "A data deletion component"
            ],
            correct: 1,
            explanation: "The decoder generates output sequences step-by-step, using self-attention on previously generated outputs and cross-attention to the encoder's representations to produce each new element."
        },
        {
            question: "What is GPT (Generative Pre-trained Transformer)?",
            options: [
                "A video game",
                "A decoder-only transformer trained to predict next tokens, used for text generation",
                "An image classifier",
                "A calculator"
            ],
            correct: 1,
            explanation: "GPT is a decoder-only transformer architecture trained on massive text data to predict the next word in a sequence, making it excellent at generating coherent, contextual text."
        },
        {
            question: "What is BERT (Bidirectional Encoder Representations from Transformers)?",
            options: [
                "A person's name",
                "An encoder-only transformer that reads text bidirectionally for understanding tasks",
                "A type of RNN",
                "A data format"
            ],
            correct: 1,
            explanation: "BERT is an encoder-only transformer that processes text bidirectionally (seeing both left and right context), making it excellent for understanding tasks like classification and question answering."
        },
        {
            question: "What does 'attention is all you need' mean?",
            options: [
                "We should pay more attention",
                "The original transformer paper showed attention mechanisms alone (without recurrence) are sufficient",
                "Only simple models are needed",
                "Training doesn't matter"
            ],
            correct: 1,
            explanation: "'Attention Is All You Need' is the groundbreaking paper that introduced transformers, showing that self-attention mechanisms alone, without recurrent layers, can achieve state-of-the-art results."
        },
        {
            question: "Why have transformers become dominant in NLP?",
            options: [
                "They are the oldest architecture",
                "They scale well with data and compute, handle long-range dependencies, and enable parallel training",
                "They are the simplest to implement",
                "They require no training"
            ],
            correct: 1,
            explanation: "Transformers dominate NLP because they scale efficiently with large datasets and compute, excel at capturing long-range dependencies, can be parallelized for fast training, and achieve superior performance."
        }
    ]
};

let userAnswers = [];
let submitted = false;

function init() {
    loadQuiz();
    loadProgress();
}

function loadQuiz() {
    const content = document.getElementById('quizContent');
    content.innerHTML = quizData.questions.map((q, index) => `
        <div class="question-card" id="question${index}">
            <div class="question-number">Question ${index + 1} of ${quizData.questions.length}</div>
            <div class="question-text">${q.question}</div>
            <div class="options">
                ${q.options.map((option, optIndex) => `
                    <div class="option" onclick="selectOption(${index}, ${optIndex})" id="q${index}_opt${optIndex}">
                        ${option}
                    </div>
                `).join('')}
            </div>
            <div class="explanation" id="explanation${index}">
                <strong>Explanation:</strong> ${q.explanation}
            </div>
        </div>
    `).join('');
}

function selectOption(questionIndex, optionIndex) {
    if (submitted) return;

    // Clear previous selection
    for (let i = 0; i < quizData.questions[questionIndex].options.length; i++) {
        document.getElementById(`q${questionIndex}_opt${i}`).classList.remove('selected');
    }

    // Mark new selection
    document.getElementById(`q${questionIndex}_opt${optionIndex}`).classList.add('selected');
    userAnswers[questionIndex] = optionIndex;

    updateProgress();
    checkSubmitEnabled();
}

function checkSubmitEnabled() {
    const allAnswered = userAnswers.length === quizData.questions.length &&
                       userAnswers.every(a => a !== undefined);
    document.getElementById('submitBtn').disabled = !allAnswered;
}

function updateProgress() {
    const progress = (userAnswers.filter(a => a !== undefined).length / quizData.questions.length) * 100;
    document.getElementById('progressBar').style.width = progress + '%';
}

function submitQuiz() {
    if (submitted) return;
    submitted = true;

    let correct = 0;

    quizData.questions.forEach((q, index) => {
        const questionCard = document.getElementById(`question${index}`);
        const userAnswer = userAnswers[index];
        const isCorrect = userAnswer === q.correct;

        if (isCorrect) {
            correct++;
            questionCard.classList.add('answered-correct');
        } else {
            questionCard.classList.add('answered-wrong');
        }

        // Show correct/wrong on options
        q.options.forEach((_, optIndex) => {
            const optEl = document.getElementById(`q${index}_opt${optIndex}`);
            optEl.classList.add('disabled');

            if (optIndex === q.correct) {
                optEl.classList.add('correct');
            } else if (optIndex === userAnswer && !isCorrect) {
                optEl.classList.add('wrong');
            }
        });

        // Show explanation
        document.getElementById(`explanation${index}`).classList.add('show');
    });

    const percentage = Math.round((correct / quizData.questions.length) * 100);

    // Save result
    const result = {
        score: correct,
        total: quizData.questions.length,
        percentage: percentage,
        date: new Date().toISOString()
    };
    localStorage.setItem(`quiz_${quizData.id}`, JSON.stringify(result));

    // Show results
    showResults(correct, percentage);
}

function showResults(correct, percentage) {
    const content = document.getElementById('quizContent');
    let message = '';
    if (percentage >= 90) message = 'Excellent! You have mastered transformer networks!';
    else if (percentage >= 70) message = 'Great job! You understand the key concepts!';
    else if (percentage >= 50) message = 'Good effort! Review the lesson to improve!';
    else message = 'Keep learning! Review the lesson and try again!';

    content.innerHTML = `
        <div class="results-card">
            <h2>Quiz Complete!</h2>
            <div class="score-display">${percentage}%</div>
            <p style="font-size: 1.3em; margin: 20px 0;">${message}</p>
            <div class="results-grid">
                <div class="result-stat">
                    <div class="result-stat-value">${correct}</div>
                    <div class="result-stat-label">Correct</div>
                </div>
                <div class="result-stat">
                    <div class="result-stat-value">${quizData.questions.length - correct}</div>
                    <div class="result-stat-label">Incorrect</div>
                </div>
                <div class="result-stat">
                    <div class="result-stat-value">${correct * 10}</div>
                    <div class="result-stat-label">Points Earned</div>
                </div>
            </div>
        </div>
    ` + content.innerHTML;

    document.getElementById('submitBtn').style.display = 'none';
    window.scrollTo({ top: 0, behavior: 'smooth' });
}

function retakeQuiz() {
    if (confirm('Retake the quiz? Your previous score will be replaced.')) {
        userAnswers = [];
        submitted = false;
        document.getElementById('submitBtn').style.display = 'inline-block';
        init();
        updateProgress();
    }
}

function loadProgress() {
    // Could load previous answers here if needed
}

// Initialize
init();
</script>
</body>
</html>
